{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "204c0e83",
   "metadata": {},
   "source": [
    "# Data Loading & Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a62864c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.feature import hog, local_binary_pattern\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "def load_images_from_folder(folder_path, target_size=(128, 128)):\n",
    "    images = []\n",
    "    labels = []\n",
    "    class_names = os.listdir(folder_path)\n",
    "    class_names.sort()\n",
    "\n",
    "    for class_name in class_names:\n",
    "        class_path = os.path.join(folder_path, class_name)\n",
    "        if os.path.isdir(class_path):\n",
    "            for filename in os.listdir(class_path):\n",
    "                img_path = os.path.join(class_path, filename)\n",
    "                if img_path.endswith(('.jpg', '.jpeg', '.png')):\n",
    "                    img = cv2.imread(img_path) #, cv2.IMREAD_GRAYSCALE\n",
    "                    if img is not None:\n",
    "                        img_resized = cv2.resize(img, target_size)\n",
    "                        \n",
    "#                         hog_features = hog(img_resized, block_norm='L2-Hys', pixels_per_cell=(16, 16))\n",
    "#                         lbp_features = local_binary_pattern(img_resized, P=8, R=1, method='uniform')\n",
    "                        images.append(img_resized.flatten()) #\n",
    "                        labels.append(class_name)\n",
    "\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# Loading training data\n",
    "train_folder_path = 'C:\\\\Users\\\\mzain\\\\Desktop\\\\Guava\\\\Nabiha\\\\dataset\\\\train_data'\n",
    "train_images, train_labels = load_images_from_folder(train_folder_path)\n",
    "\n",
    "# Loading validation data\n",
    "val_folder_path = 'C:\\\\Users\\\\mzain\\\\Desktop\\\\Guava\\\\Nabiha\\\\dataset\\\\validation_data'\n",
    "val_images, val_labels = load_images_from_folder(val_folder_path)\n",
    "\n",
    "# Loading test data\n",
    "test_folder_path = 'C:\\\\Users\\\\mzain\\\\Desktop\\\\Guava\\\\Nabiha\\\\dataset\\\\test_data'\n",
    "test_images, test_labels = load_images_from_folder(test_folder_path)\n",
    "\n",
    "# One-hot encode the labels\n",
    "label_binarizer = LabelBinarizer()\n",
    "train_labels_one_hot = label_binarizer.fit_transform(train_labels)\n",
    "val_labels_one_hot = label_binarizer.transform(val_labels)\n",
    "test_labels_one_hot = label_binarizer.transform(test_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2aa2fc93",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train_flat = train_images\n",
    "X_val_flat = val_images\n",
    "X_test_flat = test_images\n",
    "\n",
    "y_train = train_labels_one_hot\n",
    "y_val = val_labels_one_hot\n",
    "y_test = test_labels_one_hot\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a1c5c41",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\mzain\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from tensorflow.keras.preprocessing import image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e06aff9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "afc12fee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_val_flat scaled =  [[1.45205897 1.46008505 1.45973513 ... 1.48234594 1.50147173 1.53833515]\n",
      " [0.82498855 0.92691257 1.01816672 ... 1.71008152 1.68628016 1.67408641]\n",
      " [1.45205897 1.46008505 1.45973513 ... 0.94297219 1.00479906 1.04058055]\n",
      " ...\n",
      " [1.45205897 1.46008505 1.45973513 ... 1.02687477 1.08565275 1.11976878]\n",
      " [1.45205897 1.46008505 1.45973513 ... 0.96694435 1.00479906 1.06320576]\n",
      " [1.45205897 1.46008505 1.45973513 ... 0.91900002 0.98169801 1.01795534]]\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "\n",
    "scaler = StandardScaler() #67 knn\n",
    "# scaler = MinMaxScaler() #64 knn\n",
    "# scaler = RobustScaler() #69 knn\n",
    "# scaler = MaxAbsScaler() #65 knn\n",
    "\n",
    "X_train_flat = scaler.fit_transform(X_train_flat)\n",
    "X_val_flat = scaler.transform(X_val_flat)\n",
    "X_test_flat = scaler.transform(X_test_flat)\n",
    "\n",
    "print('X_val_flat scaled = ',X_val_flat)\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b65bf0",
   "metadata": {},
   "source": [
    "# 1st Model (KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "afe62d0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52789248\n"
     ]
    }
   ],
   "source": [
    "print(X_train_flat.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a5828857",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Test Accuracy: 0.9236947791164659\n",
      "KNN Model Done & Ready\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create and train the KNN classifier\n",
    "knn_model = KNeighborsClassifier(n_neighbors=3, weights='distance', metric='manhattan')\n",
    "\n",
    "knn_model.fit(X_train_flat, np.argmax(y_train, axis=1))\n",
    "\n",
    "\n",
    "# Make predictions on the validation set\n",
    "knn_val_predictions = knn_model.predict(X_val_flat)\n",
    "\n",
    "# Evaluate the model\n",
    "knn_accuracy = accuracy_score(np.argmax(y_val, axis=1), knn_val_predictions)\n",
    "print(f\"KNN Test Accuracy: {knn_accuracy}\")\n",
    "\n",
    "print('KNN Model Done & Ready') #70 @ n_neighbors=3, weights='distance', metric='manhattan' # 65 for robust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3a01899b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Validation Accuracy: 0.9196787148594378\n",
      "KNN2 Model Done & Ready\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create and train the KNN classifier\n",
    "knn2_model = KNeighborsClassifier(n_neighbors=3, weights='distance', metric='canberra')\n",
    "\n",
    "knn2_model.fit(X_train_flat, np.argmax(y_train, axis=1))\n",
    "\n",
    "\n",
    "# Make predictions on the validation set\n",
    "knn2_val_predictions = knn2_model.predict(X_val_flat)\n",
    "\n",
    "# Evaluate the model\n",
    "knn2_accuracy = accuracy_score(np.argmax(y_val, axis=1), knn2_val_predictions)\n",
    "print(f\"KNN Validation Accuracy: {knn2_accuracy}\")\n",
    "\n",
    "print('KNN2 Model Done & Ready') #70 @ n_neighbors=3, weights='distance', metric='manhattan' # 65 for robust"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e741d36",
   "metadata": {},
   "source": [
    "# 2nd Model (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f735f4dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=10)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=10)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(C=10)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create and train the SVM classifier\n",
    "svm_model = SVC(kernel='rbf', C=10) \n",
    "svm_model.fit(X_train_flat, np.argmax(y_train, axis=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "92cdba7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Test Accuracy: 0.9317269076305221\n",
      "SVM Model Done & Ready\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the validation set\n",
    "svm_val_predictions = svm_model.predict(X_val_flat)\n",
    "\n",
    "# Evaluate the model\n",
    "svm_accuracy = accuracy_score(np.argmax(y_val, axis=1), svm_val_predictions)\n",
    "print(f\"SVM Test Accuracy: {svm_accuracy}\")\n",
    "\n",
    "print('SVM Model Done & Ready') #85% @kernel='rbf', C=5  #76 for robust"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2138d3d1",
   "metadata": {},
   "source": [
    "# 3rd Model (ANN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "24947d1a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "34/34 [==============================] - 7s 136ms/step - loss: 1.1798 - accuracy: 0.5736\n",
      "Epoch 2/30\n",
      "34/34 [==============================] - 4s 131ms/step - loss: 0.8042 - accuracy: 0.6918\n",
      "Epoch 3/30\n",
      "34/34 [==============================] - 4s 131ms/step - loss: 0.6846 - accuracy: 0.7337\n",
      "Epoch 4/30\n",
      "34/34 [==============================] - 5s 134ms/step - loss: 0.6786 - accuracy: 0.7477\n",
      "Epoch 5/30\n",
      "34/34 [==============================] - 4s 131ms/step - loss: 0.5988 - accuracy: 0.7784\n",
      "Epoch 6/30\n",
      "34/34 [==============================] - 4s 131ms/step - loss: 0.5886 - accuracy: 0.7719\n",
      "Epoch 7/30\n",
      "34/34 [==============================] - 4s 130ms/step - loss: 0.5423 - accuracy: 0.8017\n",
      "Epoch 8/30\n",
      "34/34 [==============================] - 4s 131ms/step - loss: 0.5267 - accuracy: 0.8045\n",
      "Epoch 9/30\n",
      "34/34 [==============================] - 5s 133ms/step - loss: 0.5087 - accuracy: 0.8194\n",
      "Epoch 10/30\n",
      "34/34 [==============================] - 5s 133ms/step - loss: 0.5109 - accuracy: 0.8082\n",
      "Epoch 11/30\n",
      "34/34 [==============================] - 4s 132ms/step - loss: 0.4770 - accuracy: 0.8222\n",
      "Epoch 12/30\n",
      "34/34 [==============================] - 4s 131ms/step - loss: 0.5079 - accuracy: 0.8045\n",
      "Epoch 13/30\n",
      "34/34 [==============================] - 5s 136ms/step - loss: 0.4161 - accuracy: 0.8408\n",
      "Epoch 14/30\n",
      "34/34 [==============================] - 5s 134ms/step - loss: 0.4290 - accuracy: 0.8389\n",
      "Epoch 15/30\n",
      "34/34 [==============================] - 5s 132ms/step - loss: 0.3935 - accuracy: 0.8445\n",
      "Epoch 16/30\n",
      "34/34 [==============================] - 5s 134ms/step - loss: 0.4055 - accuracy: 0.8613\n",
      "Epoch 17/30\n",
      "34/34 [==============================] - 4s 130ms/step - loss: 0.3854 - accuracy: 0.8547\n",
      "Epoch 18/30\n",
      "34/34 [==============================] - 4s 131ms/step - loss: 0.3919 - accuracy: 0.8566\n",
      "Epoch 19/30\n",
      "34/34 [==============================] - 5s 133ms/step - loss: 0.3595 - accuracy: 0.8641\n",
      "Epoch 20/30\n",
      "34/34 [==============================] - 4s 132ms/step - loss: 0.3589 - accuracy: 0.8631\n",
      "Epoch 21/30\n",
      "34/34 [==============================] - 4s 130ms/step - loss: 0.3967 - accuracy: 0.8538\n",
      "Epoch 22/30\n",
      "34/34 [==============================] - 4s 130ms/step - loss: 0.3394 - accuracy: 0.8762\n",
      "Epoch 23/30\n",
      "34/34 [==============================] - 4s 132ms/step - loss: 0.3073 - accuracy: 0.8920\n",
      "Epoch 24/30\n",
      "34/34 [==============================] - 4s 130ms/step - loss: 0.3436 - accuracy: 0.8799\n",
      "Epoch 25/30\n",
      "34/34 [==============================] - 4s 130ms/step - loss: 0.3634 - accuracy: 0.8669\n",
      "Epoch 26/30\n",
      "34/34 [==============================] - 4s 132ms/step - loss: 0.3737 - accuracy: 0.8613\n",
      "Epoch 27/30\n",
      "34/34 [==============================] - 4s 131ms/step - loss: 0.3639 - accuracy: 0.8585\n",
      "Epoch 28/30\n",
      "34/34 [==============================] - 4s 132ms/step - loss: 0.3555 - accuracy: 0.8622\n",
      "Epoch 29/30\n",
      "34/34 [==============================] - 4s 131ms/step - loss: 0.3428 - accuracy: 0.8715\n",
      "Epoch 30/30\n",
      "34/34 [==============================] - 4s 130ms/step - loss: 0.3118 - accuracy: 0.8808\n",
      "8/8 [==============================] - 0s 21ms/step\n",
      "ANN Test Accuracy: 0.8273092369477911\n",
      "ANN Model Done & Ready\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import levenberg_marquardt as lm\n",
    "\n",
    "# Create and train the ANN model\n",
    "ann2_model = Sequential([\n",
    "    Dense(512, activation='elu', input_shape=(X_train_flat.shape[1],)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.2),\n",
    "    Dense(1024, activation='elu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.1),\n",
    "    Dense(512, activation='elu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.1),\n",
    "    Dense(128, activation='elu'),\n",
    "    BatchNormalization(),\n",
    "    Dense(len(np.unique(np.argmax(y_train, axis=1))), activation='softmax')  # Assuming you have a classification task\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "ann2_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "ann2_model.fit(X_train_flat, y_train, epochs=30, batch_size=32) #, validation_data=(X_test_flat, y_test)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "ann2_val_predictions = np.argmax(ann2_model.predict(X_val_flat), axis=1)\n",
    "\n",
    "# Evaluate the model\n",
    "ann2_accuracy = accuracy_score(np.argmax(y_val, axis=1), ann2_val_predictions)\n",
    "print(f\"ANN Test Accuracy: {ann2_accuracy}\")\n",
    "\n",
    "print('ANN Model Done & Ready') #86% | 80 for robust 512,0.5,1024,0.1,512,0.1,128\n",
    "\n",
    "# model_wrapper = lm.ModelWrapper(\n",
    "#     tf.keras.models.clone_model(ann2_model))\n",
    "\n",
    "# model_wrapper.compile(\n",
    "#     optimizer=tf.keras.optimizers.SGD(learning_rate=1.0),\n",
    "#     loss=lm.MeanSquaredError())\n",
    "\n",
    "# train_dataset = tf.data.Dataset.from_tensor_slices((X_train_flat, y_train))\n",
    "# train_dataset = train_dataset.shuffle(len(X_train_flat))\n",
    "# train_dataset = train_dataset.batch(1000).cache()\n",
    "# train_dataset = train_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "# # Training using Levenberg-Marquardt\n",
    "# print(\"\\n_________________________________________________________________\")\n",
    "# print(\"Train using Levenberg-Marquardt\")\n",
    "# t2_start = time.perf_counter()\n",
    "# history_lm = model_wrapper.fit(train_dataset, epochs=100)\n",
    "# t2_stop = time.perf_counter()\n",
    "# print(\"Elapsed time: \", t2_stop - t2_start)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8786cf3",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "515b1fd5",
   "metadata": {},
   "source": [
    "# 4th Model (Random Forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1263ed78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Test Accuracy: 0.927710843373494\n",
      "Random Forest Model Done & Ready\n"
     ]
    }
   ],
   "source": [
    "# Import the Random Forest classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Create and train the Random Forest classifier\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train_flat, np.argmax(y_train, axis=1))\n",
    "\n",
    "# Make predictions on the validation set\n",
    "rf_val_predictions = rf_model.predict(X_val_flat)\n",
    "\n",
    "# Evaluate the model\n",
    "rf_accuracy = accuracy_score(np.argmax(y_val, axis=1), rf_val_predictions)\n",
    "print(f\"Random Forest Test Accuracy: {rf_accuracy}\")\n",
    "\n",
    "print('Random Forest Model Done & Ready') # 70 for robust\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5948487a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c405d9bb",
   "metadata": {},
   "source": [
    "# Model Ensemble (Choose one of four methods)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a2c929a",
   "metadata": {},
   "source": [
    "## Stacking Predictions as Inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008fe063",
   "metadata": {},
   "source": [
    "### 1. To Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "546ff6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the validation set using each individual model\n",
    "knn_metatrain_predictions = knn_model.predict(X_val_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6f03343f",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn2_val_predictions = knn2_model.predict(X_val_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9a68b345",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_metatrain_predictions = svm_model.predict(X_val_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3ded5726",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 20ms/step\n"
     ]
    }
   ],
   "source": [
    "ann2_metatrain_predictions = np.argmax(ann2_model.predict(X_val_flat), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e77da689",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_metatrain_predictions = rf_model.predict(X_val_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0b34c309",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Combine individual model predictions\n",
    "X_ensemble_metatrain_predictions = np.vstack((knn_metatrain_predictions,knn2_val_predictions,ann2_metatrain_predictions,svm_metatrain_predictions, rf_metatrain_predictions)).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc40a1dc",
   "metadata": {},
   "source": [
    "### 2. To Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d2866612",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "knn_metatest_predictions = knn_model.predict(X_test_flat)\n",
    "\n",
    "knn2_test_predictions = knn2_model.predict(X_test_flat)\n",
    "\n",
    "svm_metatest_predictions = svm_model.predict(X_test_flat)\n",
    "\n",
    "ann2_metatest_predictions = np.argmax(ann2_model.predict(X_test_flat), axis=1) \n",
    "\n",
    "rf_metatest_predictions = rf_model.predict(X_test_flat)\n",
    "\n",
    "\n",
    "# Combine individual model predictions\n",
    "X_ensemble_metatest_predictions = np.vstack((knn_metatest_predictions,knn2_test_predictions,ann2_metatest_predictions,svm_metatest_predictions, rf_metatest_predictions)).T\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9813d4ea",
   "metadata": {},
   "source": [
    "## Method 1 (Ensemble) Direct Testing (No Training Step Involved)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9390dddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble Validation Accuracy: 0.9317269076305221\n",
      "Ensemble Model Done\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import mode\n",
    "\n",
    "# Take the majority vote\n",
    "final_predictions, _ = mode(X_ensemble_metatrain_predictions, axis=1)\n",
    "\n",
    "# Evaluate the ensemble model\n",
    "ensemble_accuracy = accuracy_score(np.argmax(y_val, axis=1), final_predictions.flatten()) #\n",
    "print(f\"Ensemble Validation Accuracy: {ensemble_accuracy}\")\n",
    "\n",
    "print('Ensemble Model Done') # 75%\n",
    "\n",
    "#This is actually the test accuracy because it did not used validation set for training so we used it for testing instead."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9550a7d9",
   "metadata": {},
   "source": [
    "## Method 2 (MLP Meta Learner) Train & Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0f9a5969",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble with Meta-Learner Train Accuracy: 0.963855421686747\n",
      "Meta-Learner Done\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Train MLP as a meta-learner on base model predictions\n",
    "mlp_meta_learner = MLPClassifier(hidden_layer_sizes=(16,32,16), max_iter=700)\n",
    "mlp_meta_learner.fit(X_ensemble_metatrain_predictions, np.argmax(y_val, axis=1)) #y_val\n",
    "\n",
    "# Make predictions using the meta-learner\n",
    "train_meta_learner_predictions = mlp_meta_learner.predict(X_ensemble_metatest_predictions)\n",
    "\n",
    "# Evaluate the ensemble model with the meta-learner\n",
    "meta_test_accuracy = accuracy_score(np.argmax(y_test, axis=1), train_meta_learner_predictions) #y_val\n",
    "print(f\"Ensemble with Meta-Learner Train Accuracy: {meta_test_accuracy}\")\n",
    "\n",
    "print('Meta-Learner Done')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e258cf1a",
   "metadata": {},
   "source": [
    "## Method 3 KNN Train & Test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c69264b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble with Meta-Learner (KNN) Train Accuracy: 0.9799196787148594\n",
      "Meta-Learner (KNN) Done\n"
     ]
    }
   ],
   "source": [
    "# Train KNN as a meta-learner on base model predictions\n",
    "knn_meta_learner = KNeighborsClassifier(n_neighbors=5, weights='distance', metric='manhattan')  # You can adjust the number of neighbors (n_neighbors) as needed\n",
    "knn_meta_learner.fit(X_ensemble_metatrain_predictions, np.argmax(y_val, axis=1))\n",
    "\n",
    "# Make predictions using the meta-learner\n",
    "train_knn_metalearner_predictions = knn_meta_learner.predict(X_ensemble_metatest_predictions)\n",
    "\n",
    "# Evaluate the ensemble model with the meta-learner\n",
    "knn_metatest_accuracy = accuracy_score(np.argmax(y_test, axis=1), train_knn_metalearner_predictions)\n",
    "print(f\"Ensemble with Meta-Learner (KNN) Train Accuracy: {knn_metatest_accuracy}\")\n",
    "\n",
    "print('Meta-Learner (KNN) Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fcf9e97",
   "metadata": {},
   "source": [
    "## Method 4 SVM Train & Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8ba2fdde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble with Meta-Learner Train Accuracy: 0.9678714859437751\n",
      "Meta-Learner Done\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Train SVM as a meta-learner on base model predictions\n",
    "svm_meta_learner = SVC(kernel='rbf', C=10)\n",
    "svm_meta_learner.fit(X_ensemble_metatrain_predictions, np.argmax(y_val, axis=1))\n",
    "\n",
    "# Make predictions using the meta-learner\n",
    "train_meta_learner_predictions = svm_meta_learner.predict(X_ensemble_metatest_predictions)\n",
    "\n",
    "# Evaluate the ensemble model with the meta-learner\n",
    "meta_test_accuracy = accuracy_score(np.argmax(y_test, axis=1), train_meta_learner_predictions)\n",
    "print(f\"Ensemble with Meta-Learner Train Accuracy: {meta_test_accuracy}\")\n",
    "\n",
    "print('Meta-Learner Done') #Last 95 for Guava Species\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c2535bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNN has the highest test accuracy 97.9% as a metalearner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06050c87",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
